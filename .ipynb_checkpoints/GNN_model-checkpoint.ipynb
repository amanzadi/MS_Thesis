{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Environment setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using backend: pytorch\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import dgl\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import networkx as nx\n",
    "import torch.nn as nn\n",
    "from sklearn import metrics\n",
    "from tqdm.notebook import tqdm\n",
    "import torch.nn.functional as F\n",
    "from dgl.data import DGLDataset\n",
    "#torch.cuda.set_device(0)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Setting up the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Graph(num_nodes=722, num_edges=38344,\n",
      "      ndata_schemes={'PSE': Scheme(shape=(964,), dtype=torch.float32)}\n",
      "      edata_schemes={}), Graph(num_nodes=4515, num_edges=799034,\n",
      "      ndata_schemes={'PSE': Scheme(shape=(964,), dtype=torch.float32)}\n",
      "      edata_schemes={})]\n"
     ]
    }
   ],
   "source": [
    "class PolypharmacyDataset(DGLDataset):\n",
    "    def __init__(self):\n",
    "        super().__init__(name='polypharmacy')\n",
    "\n",
    "    def process(self):\n",
    "        edges = pd.read_csv('../data/GNN_edges-toy.csv')\n",
    "        properties = pd.read_csv('../data/GNN_properties-toy.csv')\n",
    "        drug_comb = pd.read_csv('../data/GNN-TWOSIDE-train-PSE-964-toy.csv', sep=',') # or 3347\n",
    "        features = pd.read_csv('../data/GNN-GSE_full_pkd_norm.csv', index_col = 'ProteinID', sep=',')\n",
    "        \n",
    "        self.graphs = []\n",
    "        self.labels = []\n",
    "        self.comb_graphs = []\n",
    "        self.comb_labels = []\n",
    "        \n",
    "        num_features = len(features.columns) # no. of PSEs\n",
    "        self.dim_nfeats = num_features\n",
    "        self.gclasses = num_features\n",
    "\n",
    "        # Create a graph for each graph ID from the edges table.\n",
    "        # First process the properties table into two dictionaries with graph IDs as keys.\n",
    "        # The label and number of nodes are values.\n",
    "        label_dict = {}\n",
    "        num_nodes_dict = {}\n",
    "        \n",
    "        for _, row in properties.iterrows():\n",
    "            label_dict[row['graph_id']] = row['label']\n",
    "            num_nodes_dict[row['graph_id']] = row['num_nodes']\n",
    "\n",
    "        # For the edges, first group the table by graph IDs.\n",
    "        edges_group = edges.groupby('graph_id')\n",
    "        \n",
    "        #Node features or PSEs dictionary\n",
    "        feature_dic = {i+1:torch.tensor(features.loc[i+1,]) for i in range(len(features))}\n",
    "        \n",
    "        # For each graph ID...\n",
    "        for graph_id in edges_group.groups:\n",
    "            # Find the edges as well as the number of nodes and its label.\n",
    "            edges_of_id = edges_group.get_group(graph_id)\n",
    "            src = edges_of_id['src'].to_numpy()\n",
    "            dst = edges_of_id['dst'].to_numpy()\n",
    "            num_nodes = num_nodes_dict[graph_id]\n",
    "            label = label_dict[graph_id]\n",
    "            \n",
    "            # Create a graph and add it to the list of graphs and labels.\n",
    "            g = dgl.graph((src, dst), num_nodes=num_nodes)\n",
    "            \n",
    "            # Need to convert proteinsIDs for feature assigning\n",
    "            prot_ids = edges_of_id['src_prot'].unique().tolist()\n",
    "            for prot in edges_of_id['dst_prot'].unique().tolist():\n",
    "                if prot not in prot_ids:\n",
    "                    prot_ids.append(prot)\n",
    "            convert_prot = {prot_ids.index(prot):prot for prot in prot_ids}\n",
    "            \n",
    "            #Adding features of each node\n",
    "            g.ndata['PSE'] = torch.zeros(g.num_nodes(), num_features)\n",
    "            for node in g.nodes().tolist():\n",
    "                g.ndata['PSE'][node] = feature_dic[convert_prot[node]]\n",
    "                \n",
    "            self.graphs.append(g)\n",
    "            self.labels.append(label)\n",
    "        \n",
    "        # conver drugid to their respective graph id\n",
    "        #drug2graph = {properties['label'][i]:i for i in range(len(properties))} \n",
    "        drug2graph = {self.labels[i]:i for i in range(len(self.labels))} \n",
    "\n",
    "        for i in range(len(drug_comb)):\n",
    "            row = drug_comb.loc[i]\n",
    "            g1 = self.graphs[drug2graph[row[0]]] # Drug1 graph\n",
    "            g2 = self.graphs[drug2graph[row[1]]] # Drug2 graph  \n",
    "            self.comb_graphs.append([g1,g2])\n",
    "            self.comb_labels.append(torch.tensor(row[2:])) # PSE values\n",
    "\n",
    "            \n",
    "        # Convert the label list to tensor for saving.\n",
    "        #self.comb_labels = torch.LongTensor(self.comb_labels)\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "       # return self.comb_graphs[i], self.comb_labels[i]\n",
    "        return self.comb_graphs[i], self.comb_labels[i]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.comb_graphs)\n",
    "    \n",
    "\n",
    "dataset = PolypharmacyDataset()\n",
    "graph, label = dataset[0]\n",
    "print(graph)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Data loading and batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dgl.dataloading import GraphDataLoader\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "\n",
    "num_examples = len(dataset)\n",
    "num_train = int(num_examples * 0.8)\n",
    "\n",
    "train_sampler = SubsetRandomSampler(torch.arange(num_train))\n",
    "test_sampler = SubsetRandomSampler(torch.arange(num_train, num_examples))\n",
    "\n",
    "\n",
    "train_dataloader = GraphDataLoader(\n",
    "    dataset, sampler=train_sampler, batch_size=3, drop_last=False)\n",
    "test_dataloader = GraphDataLoader(\n",
    "    dataset, sampler=test_sampler, batch_size=3, drop_last=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Graph(num_nodes=7362, num_edges=1359104,\n",
      "      ndata_schemes={'PSE': Scheme(shape=(964,), dtype=torch.float32)}\n",
      "      edata_schemes={})\n"
     ]
    }
   ],
   "source": [
    "it = iter(train_dataloader)\n",
    "batch = next(it)\n",
    "print(batch[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of nodes for each graph1 element in the batch: tensor([ 694,  694, 7585])\n",
      "Number of nodes for each graph2 element in the batch: tensor([2756, 5656,  853])\n",
      "Number of edges for each graph1 element in the batch: tensor([  36906,   36906, 2270116])\n",
      "Number of edges for each graph2 element in the batch: tensor([ 292614, 1269352,   44876])\n",
      "The original graphs1 in the minibatch:\n",
      "[Graph(num_nodes=694, num_edges=36906,\n",
      "      ndata_schemes={'PSE': Scheme(shape=(964,), dtype=torch.float32)}\n",
      "      edata_schemes={}), Graph(num_nodes=694, num_edges=36906,\n",
      "      ndata_schemes={'PSE': Scheme(shape=(964,), dtype=torch.float32)}\n",
      "      edata_schemes={}), Graph(num_nodes=7585, num_edges=2270116,\n",
      "      ndata_schemes={'PSE': Scheme(shape=(964,), dtype=torch.float32)}\n",
      "      edata_schemes={})]\n"
     ]
    }
   ],
   "source": [
    "batched_graph, labels = batch\n",
    "print('Number of nodes for each graph1 element in the batch:', batched_graph[0].batch_num_nodes())\n",
    "print('Number of nodes for each graph2 element in the batch:', batched_graph[1].batch_num_nodes())\n",
    "print('Number of edges for each graph1 element in the batch:', batched_graph[0].batch_num_edges())\n",
    "print('Number of edges for each graph2 element in the batch:', batched_graph[1].batch_num_edges())\n",
    "\n",
    "# Recover the original graph elements from the minibatch\n",
    "graphs = dgl.unbatch(batched_graph[0])\n",
    "print('The original graphs1 in the minibatch:')\n",
    "print(graphs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. GNN Model: Siamese GCN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dgl.nn import GraphConv\n",
    "\n",
    "class GCN(nn.Module):\n",
    "    def __init__(self, in_feats, h_feats, num_classes):\n",
    "        super(GCN, self).__init__()\n",
    "        self.conv1 = GraphConv(in_feats, h_feats)\n",
    "        self.conv2 = GraphConv(h_feats,  num_classes)\n",
    "        \n",
    "    def forward(self, g, in_feat):\n",
    "        h = self.conv1(g, in_feat)\n",
    "        h = F.relu(h)\n",
    "        h = self.conv2(g, h)\n",
    "        g.ndata['h'] = h\n",
    "        out = F.relu(dgl.mean_nodes(g, 'h'))\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Boolean value of Tensor with more than one value is ambiguous",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n",
      "\u001b[1;32mD:\\Application\\Anaconda\\lib\\site-packages\\torch\\nn\\modules\\loss.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, weight, size_average, reduce, reduction)\u001b[0m\n\u001b[0;32m    525\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    526\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mTensor\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msize_average\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreduce\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreduction\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mstr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'mean'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 527\u001b[1;33m         \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mBCELoss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msize_average\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreduce\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreduction\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    528\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    529\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Application\\Anaconda\\lib\\site-packages\\torch\\nn\\modules\\loss.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, weight, size_average, reduce, reduction)\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[1;32mclass\u001b[0m \u001b[0m_WeightedLoss\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_Loss\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mTensor\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msize_average\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreduce\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreduction\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mstr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'mean'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 25\u001b[1;33m         \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_WeightedLoss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msize_average\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreduce\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreduction\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     26\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mregister_buffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'weight'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Application\\Anaconda\\lib\\site-packages\\torch\\nn\\modules\\loss.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, size_average, reduce, reduction)\u001b[0m\n\u001b[0;32m     16\u001b[0m         \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_Loss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0msize_average\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mreduce\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 18\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreduction\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlegacy_get_string\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msize_average\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreduce\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     19\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreduction\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mreduction\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Application\\Anaconda\\lib\\site-packages\\torch\\nn\\_reduction.py\u001b[0m in \u001b[0;36mlegacy_get_string\u001b[1;34m(size_average, reduce, emit_warning)\u001b[0m\n\u001b[0;32m     35\u001b[0m         \u001b[0mreduce\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     36\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 37\u001b[1;33m     \u001b[1;32mif\u001b[0m \u001b[0msize_average\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mreduce\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     38\u001b[0m         \u001b[0mret\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'mean'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     39\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mreduce\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Boolean value of Tensor with more than one value is ambiguous"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Create the model with given dimensions\n",
    "model = GCN(dataset.dim_nfeats, 100, dataset.gclasses)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "\n",
    "for epoch in range(5):\n",
    "    for batched_graph, labels in train_dataloader:\n",
    "        g1 = batched_graph[0]\n",
    "        g2 = batched_graph[1]\n",
    "        pred1 = model(g1, g1.ndata['PSE'].float())\n",
    "        pred2 = model(g2, g2.ndata['PSE'].float())\n",
    "        #pred = F.relu(pred1+pred2)/2)\n",
    "        pred = F.normalize(pred1+pred2)/2\n",
    "        loss = F.binary_cross_entropy(torch.sigmoid(pred).float(),labels.float())\n",
    "        #loss = 1-F.cosine_similarity(F.normalize(pred),labels).mean()\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        print ('epoch %s | loss = %s' % (epoch,loss.tolist()))\n",
    "        \n",
    "TP = 0\n",
    "FP = 0\n",
    "TN = 0\n",
    "FN = 0\n",
    "for batched_graph, labels in test_dataloader:\n",
    "    pred1 = model(batched_graph[0], batched_graph[0].ndata['PSE'].float())\n",
    "    pred2 = model(batched_graph[1], batched_graph[1].ndata['PSE'].float())\n",
    "    pred = F.normalize(pred1+pred2)/2\n",
    "\n",
    "    for i in range(len(labels)):\n",
    "        for j in range(len(labels[i])):\n",
    "            if labels[i][j] == 1 and pred[i][j] != 0:\n",
    "                TP += 1\n",
    "            elif labels[i][j] == 1 and pred[i][j] == 0:\n",
    "                FN += 1\n",
    "            elif labels[i][j] == 0 and pred[i][j] != 0:\n",
    "                FP += 1\n",
    "            elif labels[i][j] == 0 and pred[i][j] == 0:\n",
    "                TN += 1\n",
    "                pass\n",
    "            \n",
    "    # Validation metrics        \n",
    "    acc = ((TP+TN)*100)/(TP+FP+FN+TN)\n",
    "    prec = (TP*100)/(TP+FP)\n",
    "    recall = (TP*100)/(TP+FN)\n",
    "    F1 = 2*(recall*prec)/(recall+prec)\n",
    "    sim = ((F.cosine_similarity(pred.float(),labels.float())).mean().tolist())*100\n",
    "    print('Accuracy: %s | Precision: %s | Recall: %s | F1: %s | Similarity: %s' \n",
    "          %(round(acc,4),round(prec,4),round(recall,4),round(F1,4),round(sim,4)))\n",
    "'''\n",
    "roc_sc = metrics.roc_auc_score(labels.detach().numpy(), pred.detach().numpy())\n",
    "aupr_sc = metrics.average_precision_score(labels.detach().numpy(), pred.detach().numpy())\n",
    "acc = metrics.accuracy_score(label.detach().numpy(),preds.detach().numpy())\n",
    "print(roc_sc,aupr_sc,acc)\n",
    "    \n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.0062, grad_fn=<MeanBackward0>)"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred[0].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred3 =pred[0]/pred[0].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1., grad_fn=<MaxBackward1>)"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred3.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.2236, grad_fn=<MaxBackward1>)"
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred4 = F.normalize(pred)[0]\n",
    "pred4.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 : 1\n",
      "1 : 1\n",
      "2 : 1\n",
      "4 : 1\n",
      "6 : 1\n",
      "8 : 1\n",
      "9 : 1\n",
      "10 : 1\n",
      "11 : 1\n",
      "13 : 1\n",
      "14 : 1\n",
      "15 : 1\n",
      "17 : 1\n",
      "18 : 1\n",
      "19 : 1\n",
      "23 : 1\n",
      "24 : 1\n",
      "26 : 1\n",
      "27 : 1\n",
      "29 : 1\n",
      "31 : 1\n",
      "34 : 1\n",
      "35 : 1\n",
      "37 : 1\n",
      "38 : 1\n",
      "40 : 1\n",
      "41 : 1\n",
      "43 : 1\n",
      "44 : 1\n",
      "45 : 1\n",
      "48 : 1\n",
      "49 : 1\n",
      "53 : 1\n",
      "54 : 1\n",
      "55 : 1\n",
      "56 : 1\n",
      "57 : 1\n",
      "63 : 1\n",
      "71 : 1\n",
      "73 : 1\n",
      "77 : 1\n",
      "79 : 1\n",
      "80 : 1\n",
      "85 : 1\n",
      "87 : 1\n",
      "90 : 1\n",
      "102 : 1\n",
      "106 : 1\n",
      "110 : 1\n",
      "114 : 1\n",
      "116 : 1\n",
      "125 : 1\n",
      "135 : 1\n",
      "138 : 1\n",
      "140 : 1\n",
      "149 : 1\n",
      "154 : 1\n",
      "166 : 1\n",
      "167 : 1\n",
      "169 : 1\n",
      "174 : 1\n",
      "184 : 1\n",
      "186 : 1\n",
      "190 : 1\n",
      "197 : 1\n",
      "200 : 1\n",
      "201 : 1\n",
      "206 : 1\n",
      "212 : 1\n",
      "215 : 1\n",
      "225 : 1\n",
      "233 : 1\n",
      "240 : 1\n",
      "243 : 1\n",
      "247 : 1\n",
      "250 : 1\n",
      "262 : 1\n",
      "276 : 1\n",
      "278 : 1\n",
      "280 : 1\n",
      "295 : 1\n",
      "305 : 1\n",
      "314 : 1\n",
      "321 : 1\n",
      "340 : 1\n",
      "343 : 1\n",
      "345 : 1\n",
      "354 : 1\n",
      "357 : 1\n",
      "438 : 1\n",
      "456 : 1\n",
      "468 : 1\n",
      "475 : 1\n",
      "496 : 1\n",
      "499 : 1\n",
      "514 : 1\n",
      "516 : 1\n",
      "518 : 1\n",
      "547 : 1\n",
      "558 : 1\n",
      "576 : 1\n",
      "671 : 1\n",
      "731 : 1\n",
      "737 : 1\n",
      "765 : 1\n",
      "766 : 1\n",
      "838 : 1\n"
     ]
    }
   ],
   "source": [
    "pos = []\n",
    "for i, label in enumerate(labels[0].tolist()):\n",
    "    if label != 0:\n",
    "        pos.append(i)\n",
    "        print(i,':',label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 : 0.18226312100887299\n",
      "2 : 0.10972610116004944\n",
      "3 : 0.1468704342842102\n",
      "5 : 0.039318256080150604\n",
      "6 : 0.034425850957632065\n",
      "13 : 0.16543763875961304\n",
      "17 : 0.14785322546958923\n",
      "23 : 0.17088034749031067\n",
      "24 : 0.010107725858688354\n",
      "26 : 0.08054907619953156\n",
      "32 : 0.09562933444976807\n",
      "35 : 0.14744284749031067\n",
      "45 : 0.0501517616212368\n",
      "54 : 0.0092614172026515\n",
      "73 : 0.06525418907403946\n",
      "79 : 0.11941332370042801\n",
      "106 : 0.019610866904258728\n",
      "113 : 0.10846138745546341\n",
      "126 : 0.1768227368593216\n"
     ]
    }
   ],
   "source": [
    "pos2 = []\n",
    "for i, predic in enumerate(pred[0].tolist()):\n",
    "    if predic != 0:\n",
    "        pos2.append(i)\n",
    "        print(i,':',predic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "107 19\n"
     ]
    }
   ],
   "source": [
    "print(len(pos), len(pos2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ==================== Testing ===================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "edges = pd.read_csv('../data/GNN_edges-toy.csv')\n",
    "properties = pd.read_csv('../data/GNN_properties-toy.csv')\n",
    "features = pd.read_csv('../data/GNN-GSE_full_pkd_norm.csv', index_col = 'ProteinID', sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19555"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_dic = {i+1:torch.tensor(features.loc[i+1,]) for i in range(len(features))}\n",
    "len(feature_dic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>graph_id</th>\n",
       "      <th>label</th>\n",
       "      <th>num_nodes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>85</td>\n",
       "      <td>722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>119</td>\n",
       "      <td>719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>137</td>\n",
       "      <td>935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>143</td>\n",
       "      <td>5656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>146</td>\n",
       "      <td>5376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>158</td>\n",
       "      <td>2600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>159</td>\n",
       "      <td>10469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>160</td>\n",
       "      <td>6921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>175</td>\n",
       "      <td>1158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>187</td>\n",
       "      <td>6830</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   graph_id  label  num_nodes\n",
       "0         1     85        722\n",
       "1         2    119        719\n",
       "2         3    137        935\n",
       "3         4    143       5656\n",
       "4         5    146       5376\n",
       "5         6    158       2600\n",
       "6         7    159      10469\n",
       "7         8    160       6921\n",
       "8         9    175       1158\n",
       "9        10    187       6830"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "properties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>graph_id</th>\n",
       "      <th>src</th>\n",
       "      <th>dst</th>\n",
       "      <th>src_prot</th>\n",
       "      <th>dst_prot</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>76538</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>172</td>\n",
       "      <td>32</td>\n",
       "      <td>4621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76539</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>50</td>\n",
       "      <td>32</td>\n",
       "      <td>1027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76540</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>54</td>\n",
       "      <td>32</td>\n",
       "      <td>1129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76541</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>828</td>\n",
       "      <td>32</td>\n",
       "      <td>18028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76542</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>717</td>\n",
       "      <td>32</td>\n",
       "      <td>16363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126803</th>\n",
       "      <td>3</td>\n",
       "      <td>933</td>\n",
       "      <td>128</td>\n",
       "      <td>19514</td>\n",
       "      <td>3408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126804</th>\n",
       "      <td>3</td>\n",
       "      <td>933</td>\n",
       "      <td>679</td>\n",
       "      <td>19514</td>\n",
       "      <td>15709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126805</th>\n",
       "      <td>3</td>\n",
       "      <td>933</td>\n",
       "      <td>664</td>\n",
       "      <td>19514</td>\n",
       "      <td>15442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126806</th>\n",
       "      <td>3</td>\n",
       "      <td>934</td>\n",
       "      <td>420</td>\n",
       "      <td>19530</td>\n",
       "      <td>10008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126807</th>\n",
       "      <td>3</td>\n",
       "      <td>934</td>\n",
       "      <td>606</td>\n",
       "      <td>19530</td>\n",
       "      <td>14336</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>50270 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        graph_id  src  dst  src_prot  dst_prot\n",
       "76538          3    0  172        32      4621\n",
       "76539          3    0   50        32      1027\n",
       "76540          3    0   54        32      1129\n",
       "76541          3    0  828        32     18028\n",
       "76542          3    0  717        32     16363\n",
       "...          ...  ...  ...       ...       ...\n",
       "126803         3  933  128     19514      3408\n",
       "126804         3  933  679     19514     15709\n",
       "126805         3  933  664     19514     15442\n",
       "126806         3  934  420     19530     10008\n",
       "126807         3  934  606     19530     14336\n",
       "\n",
       "[50270 rows x 5 columns]"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph = edges.loc[edges['graph_id']==3]\n",
    "src = graph['src'].to_numpy()\n",
    "dst = graph['dst'].to_numpy()\n",
    "graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Graph(num_nodes=935, num_edges=50270,\n",
       "      ndata_schemes={}\n",
       "      edata_schemes={})"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g = dgl.graph((src, dst), num_nodes=935)\n",
    "g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>graph_id</th>\n",
       "      <th>src</th>\n",
       "      <th>dst</th>\n",
       "      <th>src_prot</th>\n",
       "      <th>dst_prot</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>76538</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>172</td>\n",
       "      <td>32</td>\n",
       "      <td>4621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76539</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>50</td>\n",
       "      <td>32</td>\n",
       "      <td>1027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76540</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>54</td>\n",
       "      <td>32</td>\n",
       "      <td>1129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76541</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>828</td>\n",
       "      <td>32</td>\n",
       "      <td>18028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76542</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>717</td>\n",
       "      <td>32</td>\n",
       "      <td>16363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126803</th>\n",
       "      <td>3</td>\n",
       "      <td>933</td>\n",
       "      <td>128</td>\n",
       "      <td>19514</td>\n",
       "      <td>3408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126804</th>\n",
       "      <td>3</td>\n",
       "      <td>933</td>\n",
       "      <td>679</td>\n",
       "      <td>19514</td>\n",
       "      <td>15709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126805</th>\n",
       "      <td>3</td>\n",
       "      <td>933</td>\n",
       "      <td>664</td>\n",
       "      <td>19514</td>\n",
       "      <td>15442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126806</th>\n",
       "      <td>3</td>\n",
       "      <td>934</td>\n",
       "      <td>420</td>\n",
       "      <td>19530</td>\n",
       "      <td>10008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126807</th>\n",
       "      <td>3</td>\n",
       "      <td>934</td>\n",
       "      <td>606</td>\n",
       "      <td>19530</td>\n",
       "      <td>14336</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>50270 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        graph_id  src  dst  src_prot  dst_prot\n",
       "76538          3    0  172        32      4621\n",
       "76539          3    0   50        32      1027\n",
       "76540          3    0   54        32      1129\n",
       "76541          3    0  828        32     18028\n",
       "76542          3    0  717        32     16363\n",
       "...          ...  ...  ...       ...       ...\n",
       "126803         3  933  128     19514      3408\n",
       "126804         3  933  679     19514     15709\n",
       "126805         3  933  664     19514     15442\n",
       "126806         3  934  420     19530     10008\n",
       "126807         3  934  606     19530     14336\n",
       "\n",
       "[50270 rows x 5 columns]"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "edges_group = edges.groupby('graph_id')\n",
    "edges_of_id = edges_group.get_group(3)\n",
    "edges_of_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Graph(num_nodes=935, num_edges=50270,\n",
       "      ndata_schemes={'PSE': Scheme(shape=(964,), dtype=torch.float32)}\n",
       "      edata_schemes={})"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prot_ids = edges_of_id['src_prot'].unique().tolist()\n",
    "convert_prot = {prot_ids.index(prot):prot for prot in prot_ids}\n",
    "g.ndata['PSE'] = torch.zeros(g.num_nodes(), 964)\n",
    "for node in g.nodes().tolist():\n",
    "    g.ndata['PSE'][node] = feature_dic[convert_prot[node]]\n",
    "    \n",
    "g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Arthralgia               0.781995\n",
       "Diarrhoea                0.782882\n",
       "Headache                 0.784467\n",
       "Vomiting                 0.783447\n",
       "Dyspepsia                0.780225\n",
       "                           ...   \n",
       "Hypertensive crisis      0.773061\n",
       "Pneumonia bacterial      0.712454\n",
       "Hepatocellular injury    0.782869\n",
       "Shock haemorrhagic       0.737688\n",
       "Haemorrhagic stroke      0.785618\n",
       "Name: 3291, Length: 964, dtype: float64"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features.loc[3291]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "g.ndata['PSE'][127]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "convert_prot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = dgl.graph(([0, 0, 1, 5], [1, 2, 2, 0])) # 6 nodes, 4 edges\n",
    "g\n",
    "g.ndata['x'] = th.ones(g.num_nodes(), 3)               # node feature of length 3\n",
    "g.edata['x'] = th.ones(g.num_edges(), dtype=th.int32)  # scalar integer feature\n",
    "g\n",
    "# different names can have different shapes\n",
    "g.ndata['y'] = th.randn(g.num_nodes(), 5)\n",
    "g.ndata['x'][1]                  # get node 1's feature\n",
    "g.edata['x'][th.tensor([0, 3])]  # get features of edge 0 and 3\n",
    "g.ndata['x'][0] = th.zeros(1, 3)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
